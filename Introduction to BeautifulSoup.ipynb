{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction to BeautifulSoup\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's begin with the first code you saw earlier in this lecture:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from urllib.request import urlopen\n",
    "\n",
    "html = urlopen('http://pythonscraping.com/pages/page1.html')\n",
    "print(html.read())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>This command outputs the complete HTML code for <em>page1</em> located at the URL http://pythonscraping.com/pages/page1.html. \n",
    "\n",
    "More accurately, this outputs the HTML file <em>page1.html</em>, found in the directory <em>&lt;web root&gt;/pages</em>, on the server located at the domain name <a class=\"link\" href=\"http://pythonscraping.com\">http://pythonscraping.com</a>.</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "\n",
    "**Now go to \"Module 3  Class Exercise\" notebook and complete Exercise 3.**\n",
    "\n",
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The most commonly used function in the BeautifulSoup library is `BeautifulSoup`. Let’s take a look at it in action by modifying the code above:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "from urllib.request import urlopen\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "html = urlopen('http://www.pythonscraping.com/pages/page1.html')\n",
    "bs = BeautifulSoup(html.read(), 'html.parser')\n",
    "print(bs.h1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**<font color='red'>Note 1:</font>** This returns only the *first instance* of the `h1` tag found on the page. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's see how this code actually works:\n",
    "\n",
    "<p> When you run the above code, the HTML content is transformed into a <code>BeautifulSoup</code> object, with the following structure:</p>\n",
    "\n",
    "<ul>\n",
    "\t<li>\n",
    "\t<p><strong>html</strong> → <em>&lt;html&gt;&lt;head&gt;...&lt;/head&gt;&lt;body&gt;...&lt;/body&gt;&lt;/html&gt;</em></p>\n",
    "\n",
    "\t<ul>\n",
    "\t\t<li>\n",
    "\t\t<p><strong>head</strong> → <em>&lt;head&gt;&lt;title&gt;A Useful Page&lt;title&gt;&lt;/head&gt;</em></p>\n",
    "\n",
    "\t\t<ul>\n",
    "\t\t\t<li><strong>title</strong> → <em>&lt;title&gt;A Useful Page&lt;/t</em><em>itle&gt;</em></li>\n",
    "\t\t</ul>\n",
    "\t\t</li>\n",
    "\t\t<li>\n",
    "\t\t<p><strong>body</strong> → <em>&lt;body&gt;&lt;h1&gt;An Int...&lt;/h1&gt;&lt;div&gt;Lorem ip...&lt;/div&gt;&lt;/body&gt;</em></p>\n",
    "\n",
    "\t\t<ul>\n",
    "\t\t\t<li><strong>h1</strong> → <em>&lt;h1&gt;An Interesting Title&lt;/h1&gt;</em></li>\n",
    "\t\t\t<li><strong>div</strong> → <em>&lt;div&gt;Lorem Ipsum dolor...&lt;/div&gt;</em></li>\n",
    "\t\t</ul>\n",
    "\t\t</li>\n",
    "\t</ul>\n",
    "\t</li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**<font color='red'>Note 2:</font>** You can use the `print()` funtion and the `prettify()` method to see the structure:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "print(bs.prettify())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**<font color='red'>Note 3:</font>** The `h1` tag that you extract from the page is nested two layers deep into your BeautifulSoup object structure `(html → body → h1)`. However, when you actually fetch it from the object, you call the `h1` tag directly:\n",
    "\n",
    "`bs.h1`\n",
    "\n",
    "In fact, any of the following function calls produce the same output:\n",
    "\n",
    "* <code>bs.html.body.h1</code>\n",
    "\n",
    "* <code>bs.body.h1</code>\n",
    "\n",
    "* <code>bs.html.h1</code>\n",
    "\n",
    "Give them a try in the cell below (we will discuss this in depth later on):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test different tags here:\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "\n",
    "**Now go to \"Module 3  Class Exercise\" notebook and complete Exercise 4.**\n",
    "\n",
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BeautifulSoup() input arguments:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you saw earlier, the BeautifulSoup function has two input arguments: `BeautifulSoup(markup, \"html.parser\")`. The first is the HTML text the object is based on, and the second specifies the **parser** that you want BeautifulSoup to use in order to create that object. \n",
    "\n",
    "Here are, two notes about the inputs:\n",
    "\n",
    "**<font color='red'>Note 4:</font>** Thus far, we have been calling <code>html.read()</code> in order to get the HTML content of the page as a <font color='blue'>text string</font>. BeautifulSoup can also use the <font color='blue'> file object </font> directly returned by <code>urlopen</code>, without needing to call <code>.read()</code> first:\n",
    "\n",
    "`bs = BeautifulSoup(html, 'html.parser')`\n",
    "\n",
    "**<font color='red'>Note 5:</font>** For the parser, there are four options availabe:\n",
    "\n",
    "* **Python’s html.parser:** `BeautifulSoup(markup, \"html.parser\")`\n",
    "* **lxml’s HTML parser:** \t`BeautifulSoup(markup, \"lxml\")`\t\n",
    "* **lxml’s XML parser:**    `BeautifulSoup(markup, \"lxml-xml\")` or `BeautifulSoup(markup, \"xml\")`\n",
    "* **html5lib:**             `BeautifulSoup(markup, \"html5lib\")`\n",
    "\n",
    "\n",
    "In the majority of cases, it makes no difference which parser you choose.\n",
    "\n",
    "`html.parser` is a included with Python 3 and requires no extra installations in order to use. Except where required, we will use this parser throughout this course. \n",
    "\n",
    "lxml is included in the Anaconda. If it's not installed in your version of Python, you can pip install it: pip install lxml (in the commmand line).\n",
    "\n",
    "For pros and cons of the parsers refer to [this](https://www.crummy.com/software/BeautifulSoup/bs4/doc/). Generally:\n",
    "\n",
    "* An advantage of lxml and html5lib over html.parser is that they are more lenient (i.e. better at parsing “messy” or malformed HTML codes). They are forgiving and fix problems like unclosed tags, tags that are improperly nested, and missing head or body tags.\n",
    "\n",
    "* lxml and html5lib are also somewhat faster than html.parser, although speed is not necessarily an advantage in web scraping, given that the **speed of the network itself will almost always be your largest bottleneck**. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "\n",
    "**Now go to \"Module 3  Class Exercise\" notebook and complete Exercise 5.**\n",
    "\n",
    "___"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
