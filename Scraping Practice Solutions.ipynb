{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# **Solution for Web Scraping Practice Questions**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "#### **1. Write a program that scrapes notable alumni  of Hofstra from its [wiki page](https://en.wikipedia.org/wiki/Hofstra_University). You do NOT need to handle exceptions. The output must be:**\n",
    "\n",
    "    Phillip Rosenthal, executive producer of the sitcom Everybody Loves Raymond\n",
    "    Francis Ford Coppola, film director\n",
    "    Avi Arad, founder of Marvel Studios\n",
    "    Norm Coleman, former U.S. Senator from Minnesota\n",
    "    ...\n",
    "\n",
    "**Hint:** You can use `.strip('\\n')` method to remove newlines."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from urllib.request import urlopen\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "web_address='https://en.wikipedia.org/wiki/Hofstra_University'\n",
    "html = urlopen(web_address)\n",
    "bs = BeautifulSoup(html.read(), 'html.parser')\n",
    "titles=bs.find_all('li',{ 'class':'gallerybox'})\n",
    "for title in titles:\n",
    "    print(title.get_text().strip('\\n'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **2. Write a function called `notable_alumni_finder` that takes the URL of a university's wiki page and returns its notable alumni. Handle all the possible exceptions. Test your function with the following list of URLs:**\n",
    "\n",
    "['https://en.wikipedia.org/wiki/St._John%27s_University_(New_York_City)',\n",
    "'https://en.wikipedia.org/wiki/Manhattan_College',\n",
    "'https://en.wikipedia.org/wiki/Cornell_University',\n",
    "'https://en.wikipedia.org/wiki/Columbia_University',\n",
    "'https://unknownURL.org/wiki/unknown_university']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def notable_alumni_finder(web_address):\n",
    "    \n",
    "    from urllib.request import urlopen\n",
    "    from urllib.error import HTTPError\n",
    "    from urllib.error import URLError\n",
    "    from bs4 import BeautifulSoup\n",
    "\n",
    "    print(web_address)\n",
    "    try:\n",
    "        html = urlopen(web_address)\n",
    "    except HTTPError as e:\n",
    "        print(e)\n",
    "        return None\n",
    "    except URLError as e:\n",
    "        print('The server could not be found!')\n",
    "        return None\n",
    "    bs = BeautifulSoup(html.read(), 'html.parser')\n",
    "    try:\n",
    "        alumni=bs.find_all('li',{ 'class':'gallerybox'})\n",
    "    except AttributeError as e:\n",
    "        print('Tag was not found!')\n",
    "        return None\n",
    "    else:\n",
    "        if alumni == None:\n",
    "            print ('Page has no notable alumni!')\n",
    "            return None\n",
    "        else:\n",
    "            for alum in alumni:\n",
    "                print(alum.get_text().strip('\\n'))\n",
    "            print ('---------------------------------------------')\n",
    "            return alumni     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "universities=['https://en.wikipedia.org/wiki/St._John%27s_University_(New_York_City)',\n",
    "              'https://en.wikipedia.org/wiki/Manhattan_College',\n",
    "              'https://en.wikipedia.org/wiki/Cornell_University',\n",
    "              'https://en.wikipedia.org/wiki/Columbia_University',\n",
    "              'https://unknownURL.org/wiki/unknown_university']\n",
    "\n",
    "for university in universities:\n",
    "    notable_alumni_finder(university)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **3. Write a program that scrapes and prints all the reviews on the first page of Hofstra on [Niche.com](https://www.niche.com/colleges/hofstra-university/reviews/).**\n",
    "\n",
    "**NOTE:** urlopen results in an `HTTPError: HTTP Error 403: Forbidden` error becuase of the `Python` header. As shwon below, we  can use the `request` function to send the requst with a fake header.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from urllib.request import urlopen,Request\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "web_address='https://www.niche.com/colleges/hofstra-university/reviews/'\n",
    "req = Request(web_address,headers={'User-Agent': 'Mozilla/5.0'})\n",
    "html = urlopen(req)\n",
    "\n",
    "bs = BeautifulSoup(html.read(), 'html.parser')\n",
    "titles=bs.find_all('span',{ 'class':'review__text'})\n",
    "for title in titles:\n",
    "    print(title.get_text().strip('\\n'))\n",
    "    print('--------------------------')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
