{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Putting it all together: A complete web scraping example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this example, we will scrape the car listings on Craigslist in New York and store the them in a CSV file with three columns: Listing Title, Price, and Location. \n",
    "\n",
    "Let's begin by capturing the three pieces of data from the first page: https://newyork.craigslist.org/search/cta#search=1~gallery~0~0. We create a list for each entry and put all the results on one page in a list (list of lists).\n",
    "\n",
    "Note that cars may appear in a different order in the list compared to what you see on your browser."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "344"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from urllib.request import urlopen\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "url='https://newyork.craigslist.org/search/cta#search=1~gallery~0~0'\n",
    "\n",
    "html = urlopen(url)\n",
    "bs = BeautifulSoup(html.read(),'html.parser')\n",
    "cars=bs.find_all('li',{'class':'cl-static-search-result'})\n",
    "\n",
    "scrapedCarsList=[]\n",
    "for car in cars:\n",
    "    salesTitle=car.find('div',{'class':'title'})\n",
    "    price=car.find('div',{'class':'price'})\n",
    "    location=car.find('div',{'class':'location'})\n",
    "    #Some listings do not have a price.\n",
    "    if price!=None:\n",
    "        new_car=[salesTitle.get_text().strip(),location.get_text().strip(),price.get_text().strip()]\n",
    "        #print(new_car) #uncomment to see all the cars with a newline\n",
    "        scrapedCarsList.append(new_car)\n",
    "        # print(new_car) #uncomment to see the list of cars on the first page\n",
    "len(scrapedCarsList)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's revise the code to write the results of the first page in a CSV file named `'craigslist_cars.csv'`. We can first create the file with the column titles and then append the data, as shown below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from urllib.request import urlopen\n",
    "from bs4 import BeautifulSoup\n",
    "import csv\n",
    "\n",
    "with open('craigslist_cars.csv', 'w',newline='') as myFile:\n",
    "    writer = csv.writer(myFile)\n",
    "    writer.writerow([\"Listing Title\", \"Location\", \"Price\"])\n",
    "\n",
    "url='https://newyork.craigslist.org/search/cta?s=0'\n",
    "html = urlopen(url)\n",
    "bs = BeautifulSoup(html.read(),'html.parser')\n",
    "cars=bs.find_all('li',{'class':'cl-static-search-result'})\n",
    "\n",
    "scrapedCarsList=[]\n",
    "for car in cars:\n",
    "    salesTitle=car.find('div',{'class':'title'})\n",
    "    price=car.find('div',{'class':'price'})\n",
    "    location=car.find('div',{'class':'location'})\n",
    "    #Some listings do not have a price.\n",
    "    if price!=None:\n",
    "        new_car=[salesTitle.get_text().strip(),location.get_text().strip(),price.get_text().strip()]\n",
    "        scrapedCarsList.append(new_car)\n",
    "\n",
    "with open('craigslist_cars.csv', 'a',newline='',encoding='utf-8') as myFile:\n",
    "    writer = csv.writer(myFile)\n",
    "    writer.writerows(scrapedCarsList)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How do we visit the second page, or how do we search another city, add filters like price, model year, etc.? All we need to do is to understand how these changes are reflected in the URL. After understanding the structure of the URL, we can create a list of all URLs that will be scraped later. \n",
    "\n",
    "Here is how we can create the list of URL's for the first 60 pages of listings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['https://newyork.craigslist.org/search/cta#search=1~gallery~0~0',\n",
       " 'https://newyork.craigslist.org/search/cta#search=1~gallery~1~0',\n",
       " 'https://newyork.craigslist.org/search/cta#search=1~gallery~2~0',\n",
       " 'https://newyork.craigslist.org/search/cta#search=1~gallery~3~0',\n",
       " 'https://newyork.craigslist.org/search/cta#search=1~gallery~4~0']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "urlList=[]\n",
    "for i in range(60):\n",
    "    newURL= 'https://newyork.craigslist.org/search/cta#search=1~gallery~{}~0'.format(str(i))\n",
    "    urlList.append(newURL)\n",
    "urlList[0:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next step is to convert the scraping script into a function so that we can call it on different pages.  The `craigslistCarsScrape` function takes the page number (0,1,2,..) as input and returns a list of all the cars on the page in a list of lists format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def craigslistCarsScrape(pageNumber):\n",
    "    from urllib.request import urlopen\n",
    "    from bs4 import BeautifulSoup\n",
    "    import csv\n",
    "    print('*** Scraping cars on page:',pageNumber,'***\\n\\n')\n",
    "\n",
    "    baseURL='https://newyork.craigslist.org/search/cta?s='\n",
    "    url= 'https://newyork.craigslist.org/search/cta#search=1~gallery~{}~0'.format(str(pageNumber))\n",
    "    html = urlopen(url)\n",
    "    bs = BeautifulSoup(html.read(),'html.parser')\n",
    "    cars=bs.find_all('li',{'class':'cl-static-search-result'})\n",
    "    scrapedCarsList=[]            \n",
    "    for car in cars:\n",
    "        salesTitle=car.find('div',{'class':'title'})\n",
    "        price=car.find('div',{'class':'price'})\n",
    "        location=car.find('div',{'class':'location'})\n",
    "        if price!=None:\n",
    "            new_car=[salesTitle.get_text().strip(),location.get_text().strip(),price.get_text().strip()]\n",
    "            scrapedCarsList.append(new_car)\n",
    "    return scrapedCarsList"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To make the code robust, let's add all exception handling statements. The new function is called `craigslistCarsScrapeWithExceptions`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def craigslistCarsScrapeWithExceptions(pageNumber):\n",
    "    from urllib.request import urlopen\n",
    "    from bs4 import BeautifulSoup\n",
    "    import csv\n",
    "    from urllib.error import HTTPError\n",
    "    from urllib.error import URLError\n",
    "\n",
    "    url= 'https://newyork.craigslist.org/search/cta#search=1~gallery~{}~0'.format(str(pageNumber))\n",
    "    print('*** Scraping cars on page: {} ({}) ***'.format(pageNumber,url))\n",
    "    \n",
    "    \n",
    "    try:\n",
    "        html = urlopen(url)\n",
    "    except HTTPError as e:\n",
    "        print(e)\n",
    "        print('-----------------------HTTPError----------------------')\n",
    "        return None\n",
    "    except URLError as e:\n",
    "        print('Server cound not be found')\n",
    "        print('-----------------------URLError----------------------')\n",
    "        return None\n",
    "    \n",
    "    bs = BeautifulSoup(html.read(),'html.parser')\n",
    "    \n",
    "    try:        \n",
    "        cars=bs.find_all('li',{'class':'cl-static-search-result'})\n",
    "    except AttributeError as e:\n",
    "        print('Tag was not found')\n",
    "        print('-----------------------AttributeError----------------------')\n",
    "    else:\n",
    "        if len(cars) == 0:\n",
    "            print ('Page has no cars')\n",
    "            print('---------------------No cars on the page------------------------')\n",
    "            return None\n",
    "        else:\n",
    "            scrapedCarsList=[]           \n",
    "            for car in cars:\n",
    "                salesTitle=car.find('div',{'class':'title'})\n",
    "                price=car.find('div',{'class':'price'})\n",
    "                location=car.find('div',{'class':'location'})\n",
    "                if price!=None:\n",
    "                    new_car=[salesTitle.get_text().strip(),location.get_text().strip(),price.get_text().strip()]\n",
    "                    scrapedCarsList.append(new_car)            \n",
    "            return scrapedCarsList"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we can run the function in a loop and write the resutls on a csv:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Scraping cars on page: 0 (https://newyork.craigslist.org/search/cta#search=1~gallery~0~0) ***\n",
      "*** Scraping cars on page: 1 (https://newyork.craigslist.org/search/cta#search=1~gallery~1~0) ***\n",
      "*** Scraping cars on page: 2 (https://newyork.craigslist.org/search/cta#search=1~gallery~2~0) ***\n",
      "*** Scraping cars on page: 3 (https://newyork.craigslist.org/search/cta#search=1~gallery~3~0) ***\n",
      "*** Scraping cars on page: 4 (https://newyork.craigslist.org/search/cta#search=1~gallery~4~0) ***\n",
      "*** Scraping cars on page: 5 (https://newyork.craigslist.org/search/cta#search=1~gallery~5~0) ***\n",
      "*** Scraping cars on page: 6 (https://newyork.craigslist.org/search/cta#search=1~gallery~6~0) ***\n",
      "*** Scraping cars on page: 7 (https://newyork.craigslist.org/search/cta#search=1~gallery~7~0) ***\n",
      "*** Scraping cars on page: 8 (https://newyork.craigslist.org/search/cta#search=1~gallery~8~0) ***\n",
      "*** Scraping cars on page: 9 (https://newyork.craigslist.org/search/cta#search=1~gallery~9~0) ***\n",
      "*** Scraping cars on page: 10 (https://newyork.craigslist.org/search/cta#search=1~gallery~10~0) ***\n",
      "*** Scraping cars on page: 11 (https://newyork.craigslist.org/search/cta#search=1~gallery~11~0) ***\n",
      "*** Scraping cars on page: 12 (https://newyork.craigslist.org/search/cta#search=1~gallery~12~0) ***\n",
      "*** Scraping cars on page: 13 (https://newyork.craigslist.org/search/cta#search=1~gallery~13~0) ***\n",
      "*** Scraping cars on page: 14 (https://newyork.craigslist.org/search/cta#search=1~gallery~14~0) ***\n",
      "*** Scraping cars on page: 15 (https://newyork.craigslist.org/search/cta#search=1~gallery~15~0) ***\n",
      "*** Scraping cars on page: 16 (https://newyork.craigslist.org/search/cta#search=1~gallery~16~0) ***\n",
      "*** Scraping cars on page: 17 (https://newyork.craigslist.org/search/cta#search=1~gallery~17~0) ***\n",
      "*** Scraping cars on page: 18 (https://newyork.craigslist.org/search/cta#search=1~gallery~18~0) ***\n",
      "*** Scraping cars on page: 19 (https://newyork.craigslist.org/search/cta#search=1~gallery~19~0) ***\n",
      "*** Scraping cars on page: 20 (https://newyork.craigslist.org/search/cta#search=1~gallery~20~0) ***\n",
      "*** Scraping cars on page: 21 (https://newyork.craigslist.org/search/cta#search=1~gallery~21~0) ***\n",
      "*** Scraping cars on page: 22 (https://newyork.craigslist.org/search/cta#search=1~gallery~22~0) ***\n",
      "*** Scraping cars on page: 23 (https://newyork.craigslist.org/search/cta#search=1~gallery~23~0) ***\n",
      "*** Scraping cars on page: 24 (https://newyork.craigslist.org/search/cta#search=1~gallery~24~0) ***\n",
      "*** Scraping cars on page: 25 (https://newyork.craigslist.org/search/cta#search=1~gallery~25~0) ***\n",
      "*** Scraping cars on page: 26 (https://newyork.craigslist.org/search/cta#search=1~gallery~26~0) ***\n",
      "*** Scraping cars on page: 27 (https://newyork.craigslist.org/search/cta#search=1~gallery~27~0) ***\n",
      "*** Scraping cars on page: 28 (https://newyork.craigslist.org/search/cta#search=1~gallery~28~0) ***\n",
      "*** Scraping cars on page: 29 (https://newyork.craigslist.org/search/cta#search=1~gallery~29~0) ***\n",
      "*** Scraping cars on page: 30 (https://newyork.craigslist.org/search/cta#search=1~gallery~30~0) ***\n",
      "*** Scraping cars on page: 31 (https://newyork.craigslist.org/search/cta#search=1~gallery~31~0) ***\n",
      "*** Scraping cars on page: 32 (https://newyork.craigslist.org/search/cta#search=1~gallery~32~0) ***\n",
      "*** Scraping cars on page: 33 (https://newyork.craigslist.org/search/cta#search=1~gallery~33~0) ***\n",
      "*** Scraping cars on page: 34 (https://newyork.craigslist.org/search/cta#search=1~gallery~34~0) ***\n",
      "*** Scraping cars on page: 35 (https://newyork.craigslist.org/search/cta#search=1~gallery~35~0) ***\n",
      "*** Scraping cars on page: 36 (https://newyork.craigslist.org/search/cta#search=1~gallery~36~0) ***\n",
      "*** Scraping cars on page: 37 (https://newyork.craigslist.org/search/cta#search=1~gallery~37~0) ***\n",
      "*** Scraping cars on page: 38 (https://newyork.craigslist.org/search/cta#search=1~gallery~38~0) ***\n",
      "*** Scraping cars on page: 39 (https://newyork.craigslist.org/search/cta#search=1~gallery~39~0) ***\n",
      "*** Scraping cars on page: 40 (https://newyork.craigslist.org/search/cta#search=1~gallery~40~0) ***\n",
      "*** Scraping cars on page: 41 (https://newyork.craigslist.org/search/cta#search=1~gallery~41~0) ***\n",
      "*** Scraping cars on page: 42 (https://newyork.craigslist.org/search/cta#search=1~gallery~42~0) ***\n",
      "*** Scraping cars on page: 43 (https://newyork.craigslist.org/search/cta#search=1~gallery~43~0) ***\n",
      "*** Scraping cars on page: 44 (https://newyork.craigslist.org/search/cta#search=1~gallery~44~0) ***\n",
      "*** Scraping cars on page: 45 (https://newyork.craigslist.org/search/cta#search=1~gallery~45~0) ***\n",
      "*** Scraping cars on page: 46 (https://newyork.craigslist.org/search/cta#search=1~gallery~46~0) ***\n",
      "*** Scraping cars on page: 47 (https://newyork.craigslist.org/search/cta#search=1~gallery~47~0) ***\n",
      "*** Scraping cars on page: 48 (https://newyork.craigslist.org/search/cta#search=1~gallery~48~0) ***\n",
      "*** Scraping cars on page: 49 (https://newyork.craigslist.org/search/cta#search=1~gallery~49~0) ***\n",
      "*** Scraping cars on page: 50 (https://newyork.craigslist.org/search/cta#search=1~gallery~50~0) ***\n",
      "*** Scraping cars on page: 51 (https://newyork.craigslist.org/search/cta#search=1~gallery~51~0) ***\n",
      "*** Scraping cars on page: 52 (https://newyork.craigslist.org/search/cta#search=1~gallery~52~0) ***\n",
      "*** Scraping cars on page: 53 (https://newyork.craigslist.org/search/cta#search=1~gallery~53~0) ***\n",
      "*** Scraping cars on page: 54 (https://newyork.craigslist.org/search/cta#search=1~gallery~54~0) ***\n",
      "*** Scraping cars on page: 55 (https://newyork.craigslist.org/search/cta#search=1~gallery~55~0) ***\n",
      "*** Scraping cars on page: 56 (https://newyork.craigslist.org/search/cta#search=1~gallery~56~0) ***\n",
      "*** Scraping cars on page: 57 (https://newyork.craigslist.org/search/cta#search=1~gallery~57~0) ***\n",
      "*** Scraping cars on page: 58 (https://newyork.craigslist.org/search/cta#search=1~gallery~58~0) ***\n",
      "*** Scraping cars on page: 59 (https://newyork.craigslist.org/search/cta#search=1~gallery~59~0) ***\n",
      "\n",
      "____________________¶¶¶¶¶¶¶¶¶¶¶\n",
      "___________________¶¶__________¶¶\n",
      "______¶¶¶________¶¶______________¶¶\n",
      "_____¶___¶______¶¶________________¶¶\n",
      "_____¶____¶____¶¶____¶¶______¶¶____¶¶\n",
      "_____¶____¶___¶¶____¶__¶____¶__¶____¶¶\n",
      "_____¶____¶__¶¶_____¶__¶____¶__¶_____¶¶\n",
      "____¶¶___ ¶___________________________¶¶\n",
      "____¶____¶¶¶¶¶¶_______________________¶¶\n",
      "___¶¶_________¶_¶¶¶¶¶¶¶¶¶¶¶¶¶¶¶¶¶¶¶¶__¶¶\n",
      "__¶¶____¶¶¶¶¶¶¶__¶¶___¶__¶__¶____¶¶___¶¶\n",
      "__¶____________¶__¶¶__¶__¶__¶___¶¶___¶¶\n",
      "__¶_____¶¶¶¶¶¶¶____¶¶_¶__¶__¶__¶¶___¶¶\n",
      "__¶____________¶____¶¶¶__¶__¶_¶¶___¶¶\n",
      "__¶_____¶¶¶¶¶¶¶_¶¶___¶¶¶¶¶¶¶¶¶¶___¶¶\n",
      "__¶¶__________¶___¶¶_____________¶¶\n",
      "____¶¶¶¶¶¶¶¶¶¶______¶¶_________¶¶\n",
      "______________________¶¶¶¶¶¶¶¶¶\n",
      "\n"
     ]
    }
   ],
   "source": [
    "with open('craigslist_cars_final.csv', 'w',newline='') as myFile:\n",
    "    import csv\n",
    "    writer = csv.writer(myFile)\n",
    "    writer.writerow([\"Listing Title\", \"Location\", \"Price\"])\n",
    "\n",
    "with open('craigslist_cars_final.csv', 'a',newline='',encoding='utf-8') as myFile:\n",
    "    writer = csv.writer(myFile)\n",
    "    for i in range(0,60):\n",
    "        scrapedCarsList=craigslistCarsScrapeWithExceptions(i)\n",
    "        writer.writerows(scrapedCarsList)\n",
    "\n",
    "print('''\n",
    "____________________¶¶¶¶¶¶¶¶¶¶¶\n",
    "___________________¶¶__________¶¶\n",
    "______¶¶¶________¶¶______________¶¶\n",
    "_____¶___¶______¶¶________________¶¶\n",
    "_____¶____¶____¶¶____¶¶______¶¶____¶¶\n",
    "_____¶____¶___¶¶____¶__¶____¶__¶____¶¶\n",
    "_____¶____¶__¶¶_____¶__¶____¶__¶_____¶¶\n",
    "____¶¶___ ¶___________________________¶¶\n",
    "____¶____¶¶¶¶¶¶_______________________¶¶\n",
    "___¶¶_________¶_¶¶¶¶¶¶¶¶¶¶¶¶¶¶¶¶¶¶¶¶__¶¶\n",
    "__¶¶____¶¶¶¶¶¶¶__¶¶___¶__¶__¶____¶¶___¶¶\n",
    "__¶____________¶__¶¶__¶__¶__¶___¶¶___¶¶\n",
    "__¶_____¶¶¶¶¶¶¶____¶¶_¶__¶__¶__¶¶___¶¶\n",
    "__¶____________¶____¶¶¶__¶__¶_¶¶___¶¶\n",
    "__¶_____¶¶¶¶¶¶¶_¶¶___¶¶¶¶¶¶¶¶¶¶___¶¶\n",
    "__¶¶__________¶___¶¶_____________¶¶\n",
    "____¶¶¶¶¶¶¶¶¶¶______¶¶_________¶¶\n",
    "______________________¶¶¶¶¶¶¶¶¶\n",
    "''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
